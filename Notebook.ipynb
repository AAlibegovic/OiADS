{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovaj zadatak je Python skripta za detekciju osoba u stvarnom vremenu koristeći OpenCV biblioeku koja se koristi za učitavanje mreža dubokog učenja definisanih u Caffe frameworku.\n",
    "\n",
    "Caffe (Convolutional Architecture for Fast Feature Embedding) predstavlja značajan okvir za duboko učenje, razvijen na Univerzitetu Kalifornija, Berkeley. Od svog nastanka, Caffe je prepoznat po svojoj izuzetnoj brzini, modularnosti i jednostavnosti korištenja.\n",
    "\n",
    "Jedna od najistaknutijih karakteristika Caffe-a je njegova brzina. Zahvaljujući optimizaciji za GPU, Caffe može procesirati više od nekoliko miliona slika dnevno na grafičkoj kartici. Ova performansa čini ga idealnim za aplikacije koje zahtjevaju obradu velikih količina podataka u realnom vremenu.\n",
    "\n",
    "Caffe-ova modularna arhitektura omogućava lako eksperimentisanje sa različitim konfiguracijama neuronskih mreža. Definicije modela se pišu u čitljivom i jasnom protokolnom pufer formatu, što olakšava specifikaciju i modifikaciju mrežnih arhitektura. Pored toga, Caffe podržava širok spektar zadataka dubokog učenja, uključujući klasifikaciju slika, segmentaciju, detekciju objekata i obradu video zapisa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kreiranje klase kamera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potrebno je kreirati klasu kamera i definisati instancu u main funkciji. Unutar klase definišu se osnovni paramteri za pokretanje i prikaz kamere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamera je pokrenuta...\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "class Camera:\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass  # Trenutno, nema logike inicijalizacije\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"Kamera je pokrenuta...\")\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Prikazivanje trenutnog kadra u prozoru\n",
    "            cv.imshow('Camera Feed', frame)\n",
    "\n",
    "            # Ako je pritisnuta tipka 'q', prekini petlju\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Oslobađanje resursa i zatvaranje svih OpenCV prozora\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    camera = Camera()\n",
    "    camera.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementacija detekcije "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacija detekcije osobe koristeći Caffe framework model je urađena kroz sljedeće korake:\n",
    "1. Učitava pretreniran model koristeći readNetFromCaffe.\n",
    "2. Pretprocesira trenutni kadar iz video snimka u blob format koji je pogodan za mrežu.\n",
    "3. Prolazi kroz mrežu koristeći forward da bi dobio predikcije.\n",
    "4. Obradjuje rezultate predikcije, provjerava pouzdanost detekcije i crta pravougaonik oko detektovane osobe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Učitavanje pretreniranog modela\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "net = cv.dnn.readNetFromCaffe('models/config.txt', 'models/mobilenet_iter_73000.caffemodel')\n",
    "```\n",
    "\n",
    "- cv.dnn.readNetFromCaffe(prototxt, caffemodel) - funkcija iz OpenCV biblioteke koja učitava model iz Caffe formata.\n",
    "- prototxt fajl ('models/config.txt') - sadrži definiciju strukture neuronske mreže (slojevi, parametri slojeva).\n",
    "- caffemodel fajl ('models/mobilenet_iter_73000.caffemodel') - sadrži unapred istrenirane težine mreže."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pretprocesiranje kadra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "blob = cv.dnn.blobFromImage(frame, scalefactor , size , mean)\n",
    "```\n",
    "\n",
    "cv.dnn.blobFromImage konvertuje sliku (kadar iz video snimka) u format koji može biti korišten kao ulaz za neuronsku mrežu.\n",
    "\n",
    "Parametri funkcije:\n",
    " 1. frame: trenutni kadar iz video snimka.\n",
    " 2. scalefactor: skala faktora za normalizaciju piksela.\n",
    " 3. size: dimenzije na koje se slika skalira.\n",
    " 4. mean: vrijednost koja se oduzima od svakog kanala boje (za centriranje podataka).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Postavljanje ulaza u mrežu i izvršavanje predikcije "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "self.net.setInput(blob)\n",
    "```\n",
    "\n",
    "- setInput postavlja pretprocesirani kadar (blob) kao ulaz u neuronsku mrežu.\n",
    "\n",
    "```python\n",
    "detections = self.net.forward()\n",
    "```\n",
    "\n",
    "- forward metoda izvršava prolaz unapred kroz mrežu, tj. vrši predikciju na osnovu ulaza (blob).\n",
    "\n",
    "Rezultat je niz detekcija koji mreža vraća."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Obrada rezultata predikcije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    idx = int(detections[0, 0, i, 1])\n",
    "    if idx == 15 and confidence > 0.5:\n",
    "        box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        cv.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        person_detected = True\n",
    "\n",
    "```\n",
    "\n",
    "- detections.shape[2] - daje broj detekcija.\n",
    "- Svaka detekcija ima niz atributa:\n",
    "    - detections[0, 0, i, 2] - pouzdanost detekcije (confidence).\n",
    "    - detections[0, 0, i, 1] - indeks klase detektovanog objekta.\n",
    "- Ako je detektovana osoba (indeks klase 15) i pouzdanost je veća od 0.5:\n",
    "    - detections[0, 0, i, 3:7] - koordinate pravougaonika oko detektovanog objekta, skalirane na dimenzije trenutnog kadra.\n",
    "    - cv.rectangle - crta pravougaonik oko detektovane osobe na kadru.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Oslobađanje resursa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    self.cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        print(\"Camera released...\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oslobađaju se resursi kamere i zatvaraju svi OpenCV prozori. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Puna implementacija "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamera je pokrenuta...\n",
      "Camera released...\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera:\n",
    "    \n",
    "    net = cv.dnn.readNetFromCaffe('models/config.txt', 'models/mobilenet_iter_73000.caffemodel')\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass  # Trenutno, nema logike inicijalizacije\n",
    "    \n",
    "    def run(self):\n",
    "        print(\"Kamera je pokrenuta...\")\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Pretvori kadar u blob format za unos u neuralnu mrežu\n",
    "            blob = cv.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "            \n",
    "            # Postavi blob kao unos u mrežu\n",
    "            self.net.setInput(blob)\n",
    "\n",
    "            # Izvrši predikciju koristeći mrežu\n",
    "            detections = self.net.forward()\n",
    "            person_detected = False\n",
    "\n",
    "            # Prođi kroz sve detekcije\n",
    "            for i in range(detections.shape[2]):\n",
    "                # Dobavi pouzdanost detekcije (konfidenciju)\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                \n",
    "                # Dobavi indeks klase detektovanog objekta\n",
    "                idx = int(detections[0, 0, i, 1])\n",
    "                \n",
    "                # Ako je detektovan objekat klase '15' (osoba) i konfidencija je veća od 0.5\n",
    "                if idx == 15 and confidence > 0.5:\n",
    "                    # Izračunaj koordinate pravougaonika oko detektovane osobe\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    \n",
    "                    # Nacrtaj pravougaonik oko detektovane osobe\n",
    "                    cv.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Označi da je osoba detektovana\n",
    "                    person_detected = True\n",
    "\n",
    "            # Prikazivanje trenutnog kadra u prozoru\n",
    "            cv.imshow('Camera Feed', frame)\n",
    "\n",
    "            # Ako je pritisnuta tipka 'q', prekini petlju\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Oslobađanje resursa i zatvaranje svih OpenCV prozora\n",
    "        self.cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        print(\"Camera released...\")\n",
    "\n",
    "def main():\n",
    "    camera = Camera()\n",
    "    camera.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Snimanje i spremanje videozapisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.1 Definisanje varijable za izlaz video zapisa i postavljanje međuspremnika za detekciju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "out = None\n",
    "\n",
    "```\n",
    "\n",
    "out je varijabla koja će držati objekat cv.VideoWriter kada je snimanje aktivno. Orginalno je postavljena na None što znači da snimanje nije aktivno\n",
    "\n",
    "```python\n",
    "\n",
    "buffer_duration = 5\n",
    "self.buffer_size = int(self.frame_rate * self.buffer_duration)\n",
    "self.buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "```\n",
    "- buffer_duration - definiše koliko sekundi unazad se čuva informacija o detekcijama.\n",
    "- buffer_size - izračunava koliko frejmova treba čuvati na osnovu brzine kadrova (frame rate) i trajanja međuspremnika.\n",
    "- buffer je deque (dvosmjerna lista) sa maksimalnom dužinom buffer_size, koja čuva informacije o detekcijama osoba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.2 Dodavanje rezultata detekcije u međuspremnik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "self.buffer.append(person_detected)\n",
    "\n",
    "```\n",
    "Nakon što se izvrši predikcija i proveri da li je osoba detektovana (person_detected), rezultat (True ili False) se dodaje u međuspremnik buffer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.2 Provjera i pokretanje snimanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```python\n",
    "\n",
    "if sum(self.buffer) > 0:\n",
    "    if self.out is None:\n",
    "        now = datetime.datetime.now()\n",
    "        formatted_now = now.strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "        print(\"Person motion detected at\", formatted_now)\n",
    "        current_recording_name = os.path.join('detected_videos', f'{formatted_now}.mp4')\n",
    "        fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv.VideoWriter(current_recording_name, fourcc, self.frame_rate, (frame.shape[1], frame.shape[0]))\n",
    "    self.out.write(frame)\n",
    "else:\n",
    "    if self.out is not None:\n",
    "        self.out.release()\n",
    "        self.out = None\n",
    "        print(\"Recording stopped\")\n",
    "\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provjera detekcije u međuspremniku:\n",
    "\n",
    "     -  if sum(self.buffer) > 0 - provjerava da li postoji bilo koja detekcija osobe u poslednjih buffer_duration sekundi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pokretanje snimanja:\n",
    "\n",
    "    - if self.out is None: provjerava da li je snimanje već aktivno.\n",
    "\n",
    "    - Ako nije, postavlja se novi video zapis:\n",
    "    \n",
    "        - datetime.datetime.now() - dobija trenutni datum i vrijeme.\n",
    "        - now.strftime(\"%d-%m-%y-%H-%M-%S\") - formatira datum i vrijeme za naziv fajla.\n",
    "        - current_recording_name = os.path.join('detected_videos', f'{formatted_now}.mp4') -  kreira naziv za snimljeni video fajl u direktorijumu detected_videos formata MP4\n",
    "        - cv.VideoWriter_fourcc(*'mp4v') - definiše codec za snimanje (MP4 format).\n",
    "        - self.out = cv.VideoWriter(current_recording_name, fourcc, self.frame_rate, (frame.shape[1], frame.shape[0])) - inicijalizuje objekat VideoWriter sa zadatim nazivom 'current_recording_name', brzinom kadrova '(self.frame_rate)' i veličinom kadra '(horizontalno, vertikalno)'.\n",
    "        - self.out.write(frame) - zapisuje trenutni kadar u video fajl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zaustavljanje snimanja:\n",
    "\n",
    "    - if sum(self.buffer) == 0: - provjerava da li u poslednjih buffer_duration sekundi nije bilo detekcije osoba.\n",
    "    - if self.out is not None: - provjerava da li je snimanje aktivno.\n",
    "    - self.out.release() - oslobađa resurse video zapisivača i zaustavlja snimanje.\n",
    "    - self.out = None - postavlja out na None, što znači da snimanje više nije aktivno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Spremanje u direktorij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```python\n",
    "if not os.path.exists('detected_videos'):\n",
    "    os.makedirs('detected_videos')\n",
    "```\n",
    "Provjeri da li postoji direktorijum 'detected_videos' i ako ne postoji, kreira ga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Oslobađanje resursa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prethodno oslobađanje resura se zamjenjuje sa novim\n",
    "\n",
    " ```python\n",
    "if self.out is not None:\n",
    "    self.out.release()\n",
    "    self.out = None\n",
    "\n",
    "self.cap.release()\n",
    "cv.destroyAllWindows()\n",
    "print(\"Camera released...\")\n",
    "\n",
    " ```\n",
    "\n",
    "Oslobađa se video  zapisivanje i zatvaraju svi OpenCV prozori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Puna implementacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "# Provjeri da li postoji direktorijum 'detected_videos', i ako ne postoji, kreiraj ga\n",
    "if not os.path.exists('detected_videos'):\n",
    "    os.makedirs('detected_videos')\n",
    "\n",
    "class Camera:\n",
    "    # Učitaj pretreniran model iz Caffe formata sa zadatim konfiguracionim fajlom i težinama modela\n",
    "    net = cv.dnn.readNetFromCaffe('models/config.txt', 'models/mobilenet_iter_73000.caffemodel')\n",
    "    cap = cv.VideoCapture(0)\n",
    "    \n",
    "    # Inicijalno nije postavljen izlaz za video zapis\n",
    "    out = None\n",
    "    \n",
    "    # Definiši trajanje međuspremnika u sekundama\n",
    "    buffer_duration = 5  \n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        # Postavi brzinu kadrova za kameru\n",
    "        self.frame_rate = (self.cap.get(cv.CAP_PROP_FPS)*(1/2))\n",
    "        # Izračunaj veličinu međuspremnika na osnovu brzine kadrova i trajanja međuspremnika\n",
    "        self.buffer_size = int(self.frame_rate * self.buffer_duration)\n",
    "        # Inicijalizuj deque (dvosmjernu listu) sa maksimalnom dužinom da bi veličina međuspremnika bila fiksna\n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Camera started...\")\n",
    "        while True:\n",
    "            # Čitaj trenutni kadar sa kamere\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Pretvori kadar u blob format za unos u neuralnu mrežu\n",
    "            blob = cv.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "            \n",
    "            # Postavi blob kao unos u mrežu\n",
    "            self.net.setInput(blob)\n",
    "\n",
    "            # Izvrši predikciju koristeći mrežu\n",
    "            detections = self.net.forward()\n",
    "            person_detected = False\n",
    "\n",
    "            # Prođi kroz sve detekcije\n",
    "            for i in range(detections.shape[2]):\n",
    "                # Dobavi pouzdanost detekcije (konfidenciju)\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                \n",
    "                # Dobavi indeks klase detektovanog objekta\n",
    "                idx = int(detections[0, 0, i, 1])\n",
    "                \n",
    "                # Ako je detektovan objekat klase '15' (osoba) i konfidencija je veća od 0.5\n",
    "                if idx == 15 and confidence > 0.5:\n",
    "                    # Izračunaj koordinate pravougaonika oko detektovane osobe\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    \n",
    "                    # Nacrtaj pravougaonik oko detektovane osobe\n",
    "                    cv.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Označi da je osoba detektovana\n",
    "                    person_detected = True\n",
    "\n",
    "            # Dodaj rezultat detekcije (True/False) u međuspremnik\n",
    "            self.buffer.append(person_detected)\n",
    "\n",
    "            # Provjeri da li je osoba detektovana u bilo kojem od nedavnih kadrova\n",
    "            if sum(self.buffer) > 0:  \n",
    "                # Ako nije postavljen izlaz za video, postavi ga\n",
    "                if self.out is None:\n",
    "                    # Dobavi trenutni datum i vrijeme i formatiraj ih za ime fajla\n",
    "                    now = datetime.datetime.now()\n",
    "                    formatted_now = now.strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "                    print(\"Person motion detected at\", formatted_now)\n",
    "                    \n",
    "                    # Kreiraj naziv za snimljeni video fajl\n",
    "                    current_recording_name = os.path.join('detected_videos', f'{formatted_now}.mp4')\n",
    "                    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "                    # Inicijalizuj video zapisnik sa zadatom brzinom kadrova i veličinom kadra\n",
    "                    self.out = cv.VideoWriter(current_recording_name, fourcc, self.frame_rate, (frame.shape[1], frame.shape[0]))\n",
    "                # Zapiši trenutni kadar u video fajl\n",
    "                self.out.write(frame)\n",
    "            else:\n",
    "                # Ako više nema detekcije, oslobodi resurse video zapisnika\n",
    "                if self.out is not None:\n",
    "                    self.out.release()\n",
    "                    self.out = None\n",
    "                    print(\"Recording stopped\")\n",
    "            \n",
    "            # Prikazivanje trenutnog kadra u prozoru\n",
    "            cv.imshow('Camera Feed', frame)\n",
    "\n",
    "            # Ako je pritisnuto dugme 'q', prekini petlju\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Oslobodi resurse video zapisnika ako su još uvek zauzeti\n",
    "        if self.out is not None:\n",
    "            self.out.release()\n",
    "            self.out = None\n",
    "            \n",
    "        # Oslobodi resurse kamere i zatvori sve OpenCV prozore\n",
    "        self.cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        print(\"Camera released...\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Kreiraj instancu klase Camera i pokreni metodu run\n",
    "    camera = Camera()\n",
    "    camera.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
